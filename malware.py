import os
import pandas as pd
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
import joblib

def load_data(file_path):
    """
    Load the dataset from the specified file path.

    Args:
    file_path (str): The path to the dataset file.

    Returns:
    DataFrame: The loaded dataset.
    """
    return pd.read_csv(file_path)

def split_data(data):
    """
    Split the dataset into features (X) and target variable (y).

    Args:
    data (DataFrame): The dataset to split.

    Returns:
    tuple: A tuple containing the features (X) and target variable (y).
    """
    X = data.drop(columns=["hash", "classification"])
    y = data["classification"]
    return X, y

def train_model(X_train, y_train):
    """
    Train a random forest classifier model.

    Args:
    X_train (DataFrame): The features of the training set.
    y_train (Series): The target variable of the training set.

    Returns:
    RandomForestClassifier: The trained random forest classifier model.
    """
    clf = RandomForestClassifier(n_estimators=100, random_state=42)
    clf.fit(X_train, y_train)
    return clf

def evaluate_model(model, X, y):
    """
    Evaluate the model using cross-validation.

    Args:
    model (RandomForestClassifier): The trained random forest classifier model.
    X (DataFrame): The features for evaluation.
    y (Series): The true labels for evaluation.

    Returns:
    numpy.ndarray: The cross-validation scores.
    """
    cv_scores = cross_val_score(model, X, y, cv=5)  # 5-fold cross-validation
    return cv_scores

def analyze_feature_importance(model, X):
    """
    Analyze the feature importance of the model.

    Args:
    model (RandomForestClassifier): The trained random forest classifier model.
    X (DataFrame): The features.

    Returns:
    DataFrame: The feature importance scores.
    """
    feature_importance = model.feature_importances_
    feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importance})
    feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)
    return feature_importance_df

def test_model_on_unseen_data(model, file_path):
    """
    Test the trained model on unseen data.

    Args:
    model (RandomForestClassifier): The trained random forest classifier model.
    file_path (str): The path to the unseen data file.

    Returns:
    float: The accuracy of the model on the unseen data.
    """
    new_data = pd.read_csv(file_path)
    X_new, y_new_true = split_data(new_data)
    y_new_pred = model.predict(X_new)
    accuracy_new = accuracy_score(y_new_true, y_new_pred)
    return accuracy_new

# Load the dataset
data = load_data("F:/cyber security projects/convertcsv.csv")

# Split the dataset into training and testing sets
X, y = split_data(data)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train the model
model = train_model(X_train, y_train)

# Evaluate the model using cross-validation
cv_scores = evaluate_model(model, X, y)
print("Mean cross-validation score:", cv_scores.mean())

# Analyze feature importance
feature_importance_df = analyze_feature_importance(model, X)
print("Feature Importance:")
print(feature_importance_df)

# Save the trained model
joblib.dump(model, "trained_model.pkl")
print("Trained model saved as 'trained_model.pkl'.")

# Test the model on unseen data
# Test the model on unseen data
unseen_data_file_path = "F:/cyber security projects/unseen_data.csv"
try:
    if os.path.exists(unseen_data_file_path):
        accuracy_unseen_data = test_model_on_unseen_data(model, unseen_data_file_path)
        print("Accuracy on unseen data:", accuracy_unseen_data)
    else:
        raise FileNotFoundError(f"The file '{unseen_data_file_path}' does not exist.")
except Exception as e:
    print("An error occurred:", e)



